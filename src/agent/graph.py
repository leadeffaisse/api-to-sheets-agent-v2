import requests
import os
from typing import Dict, Any, List, Optional, Annotated
from typing_extensions import TypedDict
import re
from datetime import datetime

# Chargement des variables d'environnement
from dotenv import load_dotenv
load_dotenv()

# Permettre l'import depuis MCP
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

from langgraph.graph import StateGraph, END, START
from langchain_core.messages import HumanMessage, AIMessage, BaseMessage
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
import gspread
from google.oauth2.service_account import Credentials

# =============================================================================
# CONFIGURATION DEPUIS .ENV AVEC VALEURS PAR D√âFAUT
# =============================================================================

# API Keys (SENSIBLE - depuis .env)
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
LANGSMITH_API_KEY = os.getenv("LANGSMITH_API_KEY")

# Configuration OpenAI (CONFIGURABLE - depuis .env avec d√©fauts)
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
OPENAI_TEMPERATURE = float(os.getenv("OPENAI_TEMPERATURE", "0.1"))

# Google Configuration (SENSIBLE/CONFIGURABLE - depuis .env avec d√©fauts)
GOOGLE_CREDENTIALS_PATH = os.getenv("GOOGLE_CREDENTIALS_PATH", "./google-credentials.json")
GOOGLE_PERSONAL_EMAIL = os.getenv("GOOGLE_PERSONAL_EMAIL")

# API Configuration (CONFIGURABLE - depuis .env avec d√©fauts)
DEFAULT_API_URL = os.getenv("DEFAULT_API_URL", "https://jsonplaceholder.typicode.com/posts")
API_TIMEOUT = int(os.getenv("API_TIMEOUT", "30"))
MAX_RETRIES = int(os.getenv("MAX_RETRIES", "3"))

# Limites m√©tier (CONFIGURABLE - depuis .env avec d√©fauts)
DEFAULT_LIMIT = int(os.getenv("DEFAULT_LIMIT", "10"))
MAX_LIMIT = int(os.getenv("MAX_LIMIT", "100"))
MIN_LIMIT = int(os.getenv("MIN_LIMIT", "1"))

# Google Sheets (CONFIGURABLE - depuis .env avec d√©fauts)
SHEETS_FOLDER_NAME = os.getenv("SHEETS_FOLDER_NAME", "API_Data_Exports")
SHEETS_SHARE_PUBLICLY = os.getenv("SHEETS_SHARE_PUBLICLY", "false").lower() == "true"
SHEETS_DEFAULT_TITLE_PREFIX = os.getenv("SHEETS_DEFAULT_TITLE_PREFIX", "API_Data")

# Debug et logging (CONFIGURABLE - depuis .env avec d√©fauts)
DEBUG = os.getenv("DEBUG", "false").lower() == "true"
LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO")

# LangGraph Studio Configuration (CONFIGURABLE - depuis .env avec d√©fauts)
BG_JOB_ISOLATED_LOOPS = os.getenv("BG_JOB_ISOLATED_LOOPS", "true").lower() == "true"
LANGGRAPH_STUDIO_DEBUG = os.getenv("LANGGRAPH_STUDIO_DEBUG", "true").lower() == "true"
LANGGRAPH_STUDIO_ASYNC = os.getenv("LANGGRAPH_STUDIO_ASYNC", "true").lower() == "true"

# =============================================================================
# CONFIGURATION LANGSMITH
# =============================================================================

try:
    from langsmith import Client, trace, traceable
    from langchain_core.tracers import LangChainTracer
    
    # Configuration LangSmith
    LANGSMITH_CONFIG = {
        "LANGCHAIN_TRACING_V2": os.getenv("LANGCHAIN_TRACING_V2", "true"),
        "LANGCHAIN_PROJECT": os.getenv("LANGCHAIN_PROJECT", "api-to-sheets-agent"),
        "LANGCHAIN_ENDPOINT": os.getenv("LANGCHAIN_ENDPOINT", "https://api.smith.langchain.com"),
        "LANGCHAIN_API_KEY": LANGSMITH_API_KEY or ""
    }
    
    # Appliquer la configuration LangSmith
    for key, value in LANGSMITH_CONFIG.items():
        if value:
            os.environ[key] = value
    
    # Client LangSmith
    langsmith_client = Client() if LANGSMITH_API_KEY else None
    langsmith_available = bool(LANGSMITH_API_KEY)
    
    if langsmith_available:
        print("‚úÖ LangSmith configur√© - Tracking tokens automatique activ√©")
    else:
        print("‚ö†Ô∏è LangSmith non configur√©")
    
except ImportError:
    print("‚ö†Ô∏è LangSmith non install√© - tracking tokens d√©sactiv√©")
    langsmith_client = None
    langsmith_available = False
    trace = None
    traceable = None

# =============================================================================
# FONCTIONS UTILITAIRES POUR TRACING MODERNE
# =============================================================================

def create_trace_context(name: str, tags: list = None, metadata: dict = None):
    """Cr√©e un contexte de trace compatible avec l'API moderne (sans timeout)"""
    if not langsmith_available or not trace:
        return None
    
    try:
        return trace(
            name=name,
            tags=tags or [],
            metadata=metadata or {}
        )
    except Exception as e:
        log_debug(f"Erreur cr√©ation trace (ignor√©e): {e}")
        return None

def safe_trace_update(trace_context, **kwargs):
    """Met √† jour une trace de mani√®re s√©curis√©e"""
    if trace_context:
        try:
            if hasattr(trace_context, 'update'):
                trace_context.update(**kwargs)
            elif hasattr(trace_context, 'add_metadata'):
                trace_context.add_metadata(kwargs)
        except Exception as e:
            log_debug(f"Erreur mise √† jour trace (ignor√©e): {e}")

class DummyContext:
    """Context manager dummy pour les cas o√π le tracing n'est pas disponible"""
    def __enter__(self):
        return self
    def __exit__(self, *args):
        pass
    def update(self, **kwargs):
        pass

# =============================================================================
# CONFIGURATION DU LLM AVEC NOUVEAU TRACING
# =============================================================================

callbacks = []
if langsmith_available:
    try:
        # ‚úÖ LE LANGCHAIN TRACER CAPTURE AUTOMATIQUEMENT :
        # - Tous les tokens (prompt + completion)
        # - Les co√ªts calcul√©s automatiquement
        # - Les m√©triques de performance
        # - Les erreurs et timeouts
        callbacks.append(LangChainTracer(project_name=LANGSMITH_CONFIG["LANGCHAIN_PROJECT"]))
        print(f"‚úÖ LangChain Tracer configur√© pour le projet: {LANGSMITH_CONFIG['LANGCHAIN_PROJECT']}")
        print("üí∞ Tracking automatique des tokens et co√ªts activ√©")
    except Exception as tracer_error:
        print(f"‚ö†Ô∏è Erreur configuration LangChain Tracer: {tracer_error}")

if OPENAI_API_KEY:
    llm = ChatOpenAI(
        model=OPENAI_MODEL,
        api_key=OPENAI_API_KEY,
        temperature=OPENAI_TEMPERATURE,
        timeout=API_TIMEOUT,
        max_retries=MAX_RETRIES,
        callbacks=callbacks  # ‚Üê C'est tout ce qu'il faut !
    )
else:
    llm = None

# =============================================================================
# CONFIGURATION TECHNIQUE (CONSTANTES - RESTE DANS LE CODE)
# =============================================================================

# Champs API disponibles (LOGIQUE M√âTIER - dans le code)
VALID_API_FIELDS = ["userId", "id", "title", "body"]

# Mots-cl√©s pour le parsing (LOGIQUE M√âTIER - dans le code)
FIELD_KEYWORDS = {
    "title": ["title", "titre"],
    "id": ["id", "identifiant"],
    "userId": ["userid", "user", "utilisateur"],
    "body": ["body", "contenu", "texte"]
}

RESTRICTION_KEYWORDS = ["avec", "seulement", "uniquement", "juste"]

# Google Sheets Scopes (TECHNIQUE - dans le code)
GOOGLE_SCOPES = [
    'https://www.googleapis.com/auth/spreadsheets',
    'https://www.googleapis.com/auth/drive'
]

# Patterns regex (TECHNIQUE - dans le code)
JSON_EXTRACTION_PATTERN = r'\{.*\}'
NUMBER_EXTRACTION_PATTERN = r'\b(\d+)\b'

# =============================================================================
# VALIDATION DES VARIABLES CRITIQUES
# =============================================================================

def validate_environment():
    """Valide que toutes les variables critiques sont pr√©sentes"""
    if not OPENAI_API_KEY:
        print("‚ö†Ô∏è OPENAI_API_KEY manquante dans .env")
        return False
    
    if not os.path.exists(GOOGLE_CREDENTIALS_PATH):
        print(f"‚ö†Ô∏è Fichier de credentials Google introuvable: {GOOGLE_CREDENTIALS_PATH}")
        return False
    
    return True

# Valider au chargement du module
env_valid = validate_environment()

# =============================================================================
# √âTAT TYP√â POUR LANGGRAPH
# =============================================================================

class AgentState(TypedDict):
    messages: Annotated[List[BaseMessage], "The messages in the conversation"]
    api_url: str
    user_query: str
    extracted_params: Optional[Dict[str, Any]]
    api_data: Optional[List[Dict]]
    processed_data: Optional[List[Dict]]
    sheets_url: str
    error: str

# =============================================================================
# CONFIGURATION GOOGLE SHEETS
# =============================================================================

def setup_google_sheets():
    """Configuration de l'acc√®s Google Sheets"""
    try:
        if not os.path.exists(GOOGLE_CREDENTIALS_PATH):
            print(f"‚ö†Ô∏è Fichier credentials Google introuvable: {GOOGLE_CREDENTIALS_PATH}")
            return None
            
        creds = Credentials.from_service_account_file(
            GOOGLE_CREDENTIALS_PATH, scopes=GOOGLE_SCOPES
        )
        return gspread.authorize(creds)
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur configuration Google Sheets: {e}")
        return None

gc = setup_google_sheets()

# =============================================================================
# FONCTIONS UTILITAIRES
# =============================================================================

def log_debug(message: str):
    """Log de debug si activ√©"""
    if DEBUG:
        print(f"üîç DEBUG: {message}")

def ensure_state_keys(state: AgentState) -> AgentState:
    """S'assurer que toutes les cl√©s n√©cessaires sont pr√©sentes dans l'√©tat"""
    default_state = {
        "messages": [],
        "api_url": DEFAULT_API_URL,
        "user_query": "",
        "extracted_params": None,
        "api_data": None,
        "processed_data": None,
        "sheets_url": "",
        "error": ""
    }
    
    for key, default_value in default_state.items():
        if key not in state:
            state[key] = default_value
    
    return state

# =============================================================================
# FONCTIONS PRINCIPALES (D√âFINIES AVANT build_graph)
# =============================================================================

def validate_extracted_params(params: Dict[str, Any], user_query: str) -> Dict[str, Any]:
    """Valide et corrige AGRESSIVEMENT les param√®tres extraits"""
    
    # ‚úÖ CORRECTION : Pas de timeout
    trace_context = create_trace_context(
        name="validate_extracted_params",
        tags=["validation", "parameters"],
        metadata={"step": "1.1", "component": "parameter_validator"}
    )
    
    try:
        with trace_context or DummyContext():
            user_query_lower = user_query.lower()
            log_debug(f"Validation pour: '{user_query_lower}'")
            
            safe_trace_update(trace_context, inputs={"raw_params": params, "user_query": user_query})
            
            # V√©rifier que params est un dictionnaire valide
            if not isinstance(params, dict):
                log_debug(f"Params invalide (type: {type(params)}), cr√©ation d'un nouveau dict")
                params = {}
            
            # 1. VALIDATION DU LIMIT
            try:
                numbers = re.findall(NUMBER_EXTRACTION_PATTERN, user_query)
                if numbers:
                    limit = int(numbers[0])
                    limit = max(MIN_LIMIT, min(limit, MAX_LIMIT))
                    params["limit"] = limit
                    log_debug(f"Limite corrig√©e: {params['limit']}")
                elif "limit" not in params or not isinstance(params.get("limit"), int) or params.get("limit", 0) <= 0:
                    params["limit"] = DEFAULT_LIMIT
                    log_debug(f"Limite par d√©faut: {params['limit']}")
            except Exception as limit_error:
                log_debug(f"Erreur validation limit: {limit_error}")
                params["limit"] = DEFAULT_LIMIT
            
            # 2. VALIDATION DES FIELDS
            try:
                mentioned_fields = []
                for field, keywords in FIELD_KEYWORDS.items():
                    if any(f" {keyword} " in f" {user_query_lower} " or 
                           user_query_lower.startswith(keyword + " ") or 
                           user_query_lower.endswith(" " + keyword) for keyword in keywords):
                        mentioned_fields.append(field)
                
                has_restriction_keywords = any(word in user_query_lower for word in RESTRICTION_KEYWORDS)
                
                if mentioned_fields and has_restriction_keywords:
                    params["fields"] = mentioned_fields
                elif not mentioned_fields:
                    params["fields"] = VALID_API_FIELDS[:]
                else:
                    if "fields" not in params or not isinstance(params.get("fields"), list):
                        params["fields"] = VALID_API_FIELDS[:]
                    else:
                        params["fields"] = [field for field in params["fields"] if field in VALID_API_FIELDS]
                        if not params["fields"]:
                            params["fields"] = VALID_API_FIELDS[:]
            except Exception as fields_error:
                log_debug(f"Erreur validation fields: {fields_error}")
                params["fields"] = VALID_API_FIELDS[:]
            
            # 3. VALIDATION DES FILTERS
            try:
                if "filters" not in params or not isinstance(params.get("filters"), dict):
                    params["filters"] = {}
            except Exception as filters_error:
                log_debug(f"Erreur validation filters: {filters_error}")
                params["filters"] = {}
            
            # 4. VALIDATION DE LA DESCRIPTION
            try:
                if "description" not in params or not isinstance(params.get("description"), str):
                    params["description"] = f"R√©cup√©ration de {params['limit']} posts avec les champs {', '.join(params['fields'])}"
            except Exception as desc_error:
                log_debug(f"Erreur validation description: {desc_error}")
                params["description"] = f"R√©cup√©ration de donn√©es"
            
            safe_trace_update(trace_context, outputs={"validated_params": params})
            
            log_debug(f"Validation termin√©e avec succ√®s: {params}")
            return params
    
    except Exception as e:
        log_debug(f"Erreur dans validate_extracted_params: {type(e).__name__}: {str(e)}")
        # En cas d'erreur, retourner des param√®tres par d√©faut valides
        fallback_params = {
            "limit": DEFAULT_LIMIT,
            "fields": VALID_API_FIELDS[:],
            "filters": {},
            "description": f"Param√®tres par d√©faut suite √† une erreur de validation"
        }
        log_debug(f"Retour de param√®tres fallback: {fallback_params}")
        return fallback_params

def parse_user_query(state: AgentState) -> AgentState:
    """Parse la requ√™te utilisateur pour extraire les param√®tres"""
    
    log_debug(f"=== D√âBUT PARSE_USER_QUERY ===")
    
    # ‚úÖ CORRECTION : Pas de timeout
    trace_context = create_trace_context(
        name="parse_user_query",
        tags=["parsing", "user_input"],
        metadata={"step": "1", "component": "query_parser"}
    )
    
    try:
        with trace_context or DummyContext():
            log_debug(f"VERSION MISE √Ä JOUR CHARG√âE - TIMESTAMP: {datetime.now()}")
            
            # R√©cup√©rer la derni√®re requ√™te utilisateur
            user_query = ""
            messages = state.get("messages", [])
            
            for message in reversed(messages):
                if isinstance(message, dict):
                    if message.get('type') == 'human' and message.get('content'):
                        user_query = message['content']
                        break
                elif isinstance(message, HumanMessage):
                    user_query = message.content
                    break
            
            safe_trace_update(trace_context, 
                inputs={"user_query": user_query, "messages_count": len(messages)}
            )
            
            log_debug(f"Requ√™te √† analyser: '{user_query}'")
            
            if not llm:
                state["error"] = "LLM non configur√© - v√©rifiez OPENAI_API_KEY"
                log_debug(f"=== FIN PARSE_USER_QUERY (erreur LLM) ===")
                return state
            
            if not user_query.strip():
                state["error"] = "Requ√™te utilisateur vide"
                log_debug(f"=== FIN PARSE_USER_QUERY (requ√™te vide) ===")
                return state
            
            prompt = ChatPromptTemplate.from_template(
                "Analyse la requ√™te utilisateur et g√©n√®re un JSON structur√© pour requ√™te API.\n"
                "Requ√™te: {user_query}\n"
                "R√©ponds uniquement avec le JSON contenant les cl√©s: limit, fields, filters, description."
            )

            parser = JsonOutputParser()

            chain = prompt | llm | parser

            log_debug("‚ö° Appel du LLM pour parsing de la requ√™te utilisateur")
            params = chain.invoke({"user_query": user_query})
            
            # Validation et nettoyage des param√®tres
            log_debug("D√©but validation des param√®tres")
            validated_params = validate_extracted_params(params, user_query)
            log_debug("Fin validation des param√®tres")
            
            state["extracted_params"] = validated_params
            state["user_query"] = user_query
            
            # Ne pas d√©finir d'erreur si tout va bien
            if "error" in state:
                del state["error"]
            
            safe_trace_update(trace_context,
                outputs={
                    "extracted_params": validated_params,
                    "parsing_success": True
                }
            )
            
            log_debug(f"Param√®tres finaux: {validated_params}")
            log_debug(f"=== FIN PARSE_USER_QUERY (succ√®s) ===")
                
    except Exception as e:
        error_msg = f"Erreur lors du parsing: {str(e)}"
        log_debug(f"Exception dans parse_user_query: {type(e).__name__}: {str(e)}")
        
        # Essayer de cr√©er des param√®tres fallback m√™me en cas d'erreur
        try:
            log_debug("Tentative de cr√©ation de param√®tres fallback d'urgence")
            params = create_fallback_params(user_query if 'user_query' in locals() else "r√©cup√©rer des posts")
            validated_params = validate_extracted_params(params, user_query if 'user_query' in locals() else "")
            state["extracted_params"] = validated_params
            state["user_query"] = user_query if 'user_query' in locals() else ""
            log_debug(f"Param√®tres fallback d'urgence cr√©√©s: {validated_params}")
            # Ne pas d√©finir d'erreur si on a pu cr√©er des param√®tres
            if "error" in state:
                del state["error"]
        except Exception as fallback_error:
            log_debug(f"Erreur cr√©ation fallback d'urgence: {fallback_error}")
            state["error"] = error_msg
        
        safe_trace_update(trace_context,
            outputs={"error": error_msg, "parsing_success": False}
        )
        
        log_debug(f"=== FIN PARSE_USER_QUERY (erreur) ===")
    
    return state

def create_fallback_params(user_query: str) -> Dict[str, Any]:
    """Cr√©e des param√®tres par d√©faut bas√©s sur une analyse simple de la requ√™te"""
    
    log_debug(f"Cr√©ation de param√®tres fallback pour: '{user_query}'")
    
    try:
        # Analyse simple pour extraire le nombre
        numbers = re.findall(r'\b(\d+)\b', user_query)
        limit = int(numbers[0]) if numbers else DEFAULT_LIMIT
        limit = max(MIN_LIMIT, min(limit, MAX_LIMIT))
        
        # Analyse simple pour les champs
        user_query_lower = user_query.lower()
        mentioned_fields = []
        
        for field, keywords in FIELD_KEYWORDS.items():
            if any(keyword in user_query_lower for keyword in keywords):
                mentioned_fields.append(field)
        
        # V√©rifier les mots de restriction
        has_restriction = any(word in user_query_lower for word in RESTRICTION_KEYWORDS)
        
        if mentioned_fields and has_restriction:
            fields = mentioned_fields[:]  # Copie de la liste
        else:
            fields = VALID_API_FIELDS[:]  # Copie de la liste
        
        params = {
            "limit": limit,
            "fields": fields,
            "filters": {},
            "description": f"R√©cup√©ration de {limit} posts avec les champs {', '.join(fields)} (fallback)"
        }
        
        log_debug(f"Param√®tres fallback cr√©√©s: {params}")
        return params
        
    except Exception as e:
        log_debug(f"Erreur dans create_fallback_params: {e}")
        # Param√®tres d'urgence
        return {
            "limit": DEFAULT_LIMIT,
            "fields": VALID_API_FIELDS[:],
            "filters": {},
            "description": "Param√®tres d'urgence"
        }

def fetch_api_data(state: AgentState) -> AgentState:
    """R√©cup√®re les donn√©es depuis l'API"""
    
    trace_context = None
    if langsmith_client:
        try:
            trace_context = langsmith_client.trace(
                name="fetch_api_data",
                tags=["api", "data_fetching"],
                metadata={"step": "2", "component": "api_client"}
            ).__enter__()
        except:
            pass
    
    try:
        state = ensure_state_keys(state)
        
        if state.get("error"):
            if trace_context:
                trace_context.update(outputs={"skipped": True, "reason": "previous_error"})
            return state
        
        if "api_url" not in state or not state["api_url"]:
            state["api_url"] = DEFAULT_API_URL
        
        if trace_context:
            trace_context.update(inputs={
                "api_url": state["api_url"],
                "extracted_params": state.get("extracted_params", {})
            })
        
        log_debug(f"Appel API: {state['api_url']}")
        response = requests.get(state["api_url"], timeout=API_TIMEOUT)
        response.raise_for_status()
        
        all_data = response.json()
        
        # Application des filtres
        if state.get("extracted_params") and "filters" in state["extracted_params"]:
            filters = state["extracted_params"]["filters"]
            for key, value in filters.items():
                if key in ["userId", "id"]:
                    all_data = [item for item in all_data if item.get(key) == int(value)]
        
        # Limitation du nombre de r√©sultats
        limit = state["extracted_params"].get("limit", DEFAULT_LIMIT) if state.get("extracted_params") else DEFAULT_LIMIT
        state["api_data"] = all_data[:limit]
        
        if trace_context:
            trace_context.update(outputs={
                "success": True,
                "total_items": len(all_data),
                "filtered_items": len(state["api_data"]),
                "limit_applied": limit
            })
        
        log_debug(f"Donn√©es API r√©cup√©r√©es: {len(state['api_data'])} √©l√©ments")
        
    except Exception as e:
        error_msg = f"Erreur lors de la r√©cup√©ration API: {str(e)}"
        state["error"] = error_msg
        
        if trace_context:
            trace_context.update(outputs={"success": False, "error": error_msg})
        print(f"Erreur: {state['error']}")
    
    finally:
        if trace_context:
            trace_context.__exit__(None, None, None)
    
    return state

def process_data(state: AgentState) -> AgentState:
    """Traite et filtre les donn√©es selon les champs demand√©s"""
    
    trace_context = None
    if langsmith_client:
        try:
            trace_context = langsmith_client.trace(
                name="process_data",
                tags=["processing", "data_transformation"],
                metadata={"step": "3", "component": "data_processor"}
            ).__enter__()
        except:
            pass
    
    try:
        state = ensure_state_keys(state)
        
        if state.get("error") or not state.get("api_data"):
            if trace_context:
                trace_context.update(outputs={"skipped": True, "reason": "no_data_or_error"})
            return state
        
        fields = VALID_API_FIELDS
        if state.get("extracted_params") and "fields" in state["extracted_params"]:
            fields = state["extracted_params"]["fields"]
        
        if trace_context:
            trace_context.update(inputs={
                "raw_data_count": len(state["api_data"]),
                "fields_to_extract": fields
            })
        
        processed_data = []
        for item in state["api_data"]:
            filtered_item = {}
            for field in fields:
                if field in item:
                    filtered_item[field] = item[field]
            processed_data.append(filtered_item)
        
        state["processed_data"] = processed_data
        
        if trace_context:
            trace_context.update(outputs={
                "success": True,
                "processed_items": len(processed_data),
                "extracted_fields": fields
            })
        
        log_debug(f"Donn√©es trait√©es: {len(processed_data)} √©l√©ments avec champs {fields}")
        
    except Exception as e:
        error_msg = f"Erreur lors du traitement: {str(e)}"
        state["error"] = error_msg
        
        if trace_context:
            trace_context.update(outputs={"success": False, "error": error_msg})
        print(f"Erreur: {state['error']}")
    
    finally:
        if trace_context:
            trace_context.__exit__(None, None, None)
    
    return state

def create_google_sheet(state: AgentState) -> AgentState:
    """Cr√©e un Google Sheet et y ajoute les donn√©es dans un dossier organis√©"""
    
    # ‚úÖ CORRECTION : Supprimer le param√®tre timeout
    trace_context = create_trace_context(
        name="create_google_sheet",
        tags=["google_sheets", "export"],
        metadata={"step": "4", "component": "sheets_creator"}
    )
    
    try:
        with trace_context or DummyContext():
            state = ensure_state_keys(state)
            
            if state.get("error") or not state.get("processed_data") or not gc:
                if not gc:
                    error_msg = "Google Sheets non configur√©"
                    state["error"] = error_msg
                    safe_trace_update(trace_context, outputs={"success": False, "error": error_msg})
                else:
                    safe_trace_update(trace_context, outputs={"skipped": True, "reason": "no_data_or_error"})
                return state
            
            processed_data = state["processed_data"]
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            sheet_title = f"{SHEETS_DEFAULT_TITLE_PREFIX}_{timestamp}"
            
            safe_trace_update(trace_context, inputs={
                "data_count": len(processed_data),
                "sheet_title": sheet_title,
                "folder_name": SHEETS_FOLDER_NAME
            })
            
            log_debug(f"Cr√©ation du sheet: {sheet_title}")
            
            # =================================================================
            # 1. SETUP DES CREDENTIALS POUR DRIVE API
            # =================================================================
            folder_id = None
            drive_service = None
            
            try:
                from googleapiclient.discovery import build
                from google.oauth2.service_account import Credentials
                
                log_debug(f"Chargement des credentials depuis: {GOOGLE_CREDENTIALS_PATH}")
                
                # Cr√©er les credentials avec les scopes Drive
                creds = Credentials.from_service_account_file(
                    GOOGLE_CREDENTIALS_PATH, 
                    scopes=GOOGLE_SCOPES
                )
                
                # Cr√©er le service Drive
                drive_service = build('drive', 'v3', credentials=creds)
                log_debug("‚úÖ Service Drive API initialis√©")
                
                # =================================================================
                # 2. RECHERCHER/CR√âER LE DOSSIER
                # =================================================================
                log_debug(f"Recherche du dossier '{SHEETS_FOLDER_NAME}'...")
                
                # Rechercher si le dossier existe d√©j√†
                search_query = f"name='{SHEETS_FOLDER_NAME}' and mimeType='application/vnd.google-apps.folder' and trashed=false"
                results = drive_service.files().list(
                    q=search_query,
                    fields="files(id, name, parents)"
                ).execute()
                
                folders = results.get('files', [])
                log_debug(f"Dossiers trouv√©s: {len(folders)}")
                
                if folders:
                    folder_id = folders[0]['id']
                    log_debug(f"‚úÖ Dossier trouv√©: {SHEETS_FOLDER_NAME} (ID: {folder_id})")
                else:
                    # Cr√©er le dossier s'il n'existe pas
                    log_debug(f"üîß Cr√©ation du dossier '{SHEETS_FOLDER_NAME}'...")
                    folder_metadata = {
                        'name': SHEETS_FOLDER_NAME,
                        'mimeType': 'application/vnd.google-apps.folder'
                    }
                    
                    folder = drive_service.files().create(
                        body=folder_metadata,
                        fields='id'
                    ).execute()
                    
                    folder_id = folder.get('id')
                    log_debug(f"‚úÖ Dossier cr√©√©: {SHEETS_FOLDER_NAME} (ID: {folder_id})")
                    
                    # Partager le dossier avec l'email personnel
                    if GOOGLE_PERSONAL_EMAIL:
                        try:
                            permission = {
                                'type': 'user',
                                'role': 'writer',
                                'emailAddress': GOOGLE_PERSONAL_EMAIL
                            }
                            drive_service.permissions().create(
                                fileId=folder_id,
                                body=permission,
                                sendNotificationEmail=False
                            ).execute()
                            log_debug(f"‚úÖ Dossier partag√© avec {GOOGLE_PERSONAL_EMAIL}")
                        except Exception as share_error:
                            log_debug(f"‚ö†Ô∏è Erreur partage dossier: {share_error}")
                    
            except ImportError:
                log_debug("‚ùå google-api-python-client non install√©")
                log_debug("üìù Installez avec: pip install google-api-python-client")
                drive_service = None
            except FileNotFoundError:
                log_debug(f"‚ùå Fichier credentials non trouv√©: {GOOGLE_CREDENTIALS_PATH}")
                drive_service = None
            except Exception as drive_error:
                log_debug(f"‚ö†Ô∏è Erreur lors de la configuration Drive API: {drive_error}")
                log_debug("üìù Le sheet sera cr√©√© √† la racine de Drive")
                drive_service = None
            
            # =================================================================
            # 3. CR√âER LE GOOGLE SHEET
            # =================================================================
            log_debug("Cr√©ation du Google Sheet...")
            sheet = gc.create(sheet_title)
            sheet_id = sheet.id
            log_debug(f"‚úÖ Sheet cr√©√©: {sheet_title} (ID: {sheet_id})")
            
            # =================================================================
            # 4. D√âPLACER LE SHEET DANS LE DOSSIER
            # =================================================================
            if folder_id and drive_service:
                try:
                    log_debug(f"üîß D√©placement du sheet dans le dossier '{SHEETS_FOLDER_NAME}'...")
                    
                    # R√©cup√©rer les parents actuels du fichier
                    file_metadata = drive_service.files().get(
                        fileId=sheet_id, 
                        fields='parents'
                    ).execute()
                    
                    previous_parents = ",".join(file_metadata.get('parents', []))
                    log_debug(f"Parents actuels: {previous_parents}")
                    
                    # D√©placer le fichier vers le nouveau dossier
                    drive_service.files().update(
                        fileId=sheet_id,
                        addParents=folder_id,
                        removeParents=previous_parents,
                        fields='id, parents'
                    ).execute()
                    
                    log_debug(f"‚úÖ Sheet d√©plac√© dans le dossier '{SHEETS_FOLDER_NAME}'")
                    
                    # V√©rifier le d√©placement
                    updated_file = drive_service.files().get(
                        fileId=sheet_id,
                        fields='parents'
                    ).execute()
                    log_debug(f"Nouveaux parents: {updated_file.get('parents', [])}")
                    
                except Exception as move_error:
                    log_debug(f"‚ö†Ô∏è Erreur lors du d√©placement: {move_error}")
                    log_debug("üìù Le sheet reste √† la racine mais est utilisable")
            else:
                if not folder_id:
                    log_debug("‚ö†Ô∏è Pas de folder_id - sheet cr√©√© √† la racine")
                if not drive_service:
                    log_debug("‚ö†Ô∏è Pas de drive_service - sheet cr√©√© √† la racine")
            
            # =================================================================
            # 5. PARTAGER LE SHEET
            # =================================================================
            if GOOGLE_PERSONAL_EMAIL:
                try:
                    sheet.share(GOOGLE_PERSONAL_EMAIL, perm_type='user', role='writer')
                    log_debug(f"‚úÖ Sheet partag√© avec {GOOGLE_PERSONAL_EMAIL}")
                except Exception as share_error:
                    log_debug(f"‚ö†Ô∏è Erreur partage sheet: {share_error}")
            
            # Partage public si configur√©
            if SHEETS_SHARE_PUBLICLY:
                try:
                    sheet.share('', perm_type='anyone', role='reader')
                    log_debug("‚úÖ Sheet partag√© publiquement en lecture")
                except Exception as public_error:
                    log_debug(f"‚ö†Ô∏è Impossible de partager publiquement: {public_error}")
            
            # =================================================================
            # 6. AJOUTER LES DONN√âES
            # =================================================================
            worksheet = sheet.get_worksheet(0)
            
            if processed_data:
                # En-t√™tes
                headers = list(processed_data[0].keys())
                worksheet.append_row(headers)
                log_debug(f"‚úÖ En-t√™tes ajout√©s: {headers}")
                
                # Donn√©es
                for item in processed_data:
                    row_values = [item.get(header, '') for header in headers]
                    worksheet.append_row(row_values)
                
                log_debug(f"‚úÖ {len(processed_data)} lignes de donn√©es ajout√©es")
            
            # =================================================================
            # 7. CONSTRUIRE L'URL FINALE
            # =================================================================
            state["sheets_url"] = sheet.url
            
            # Construire l'URL du dossier si disponible
            folder_url = None
            if folder_id:
                folder_url = f"https://drive.google.com/drive/folders/{folder_id}"
                log_debug(f"üìÅ Dossier Google Drive: {folder_url}")
                log_debug(f"üìä Google Sheet: {sheet.url}")
                log_debug(f"üéØ Le sheet a √©t√© organis√© dans le dossier '{SHEETS_FOLDER_NAME}'")
            else:
                log_debug(f"üìä Google Sheet (racine Drive): {sheet.url}")
            
            safe_trace_update(trace_context, outputs={
                "success": True,
                "sheet_url": sheet.url,
                "sheet_id": sheet_id,
                "folder_id": folder_id,
                "folder_url": folder_url,
                "rows_added": len(processed_data),
                "moved_to_folder": bool(folder_id and drive_service)
            })
            
            log_debug(f"Google Sheet cr√©√© avec succ√®s: {sheet.url}")
            
    except Exception as e:
        error_msg = f"Erreur lors de la cr√©ation du Google Sheet: {str(e)}"
        state["error"] = error_msg
        
        safe_trace_update(trace_context, outputs={"success": False, "error": error_msg})
        log_debug(f"‚ùå Erreur: {state['error']}")
        
        # Debug d√©taill√©
        import traceback
        log_debug(f"Stack trace: {traceback.format_exc()}")
    
    return state

def generate_response(state: AgentState) -> AgentState:
    """G√©n√®re la r√©ponse finale avec lien vers les stats LangSmith"""
    
    state = ensure_state_keys(state)
    
    if state.get("error"):
        response = f"‚ùå Erreur: {state['error']}"
    else:
        params = state.get("extracted_params", {})
        
        response = f"""‚úÖ T√¢che termin√©e avec succ√®s !

üìä **Donn√©es r√©cup√©r√©es:**
- {len(state.get('processed_data', []))} posts trait√©s
- Champs extraits: {', '.join(params.get('fields', ['tous']))}
- Limite appliqu√©e: {params.get('limit', DEFAULT_LIMIT)}

üìã **Google Sheet cr√©√©:**
{state.get('sheets_url', 'Non disponible')}

üîó Vous pouvez maintenant acc√©der √† vos donn√©es dans le Google Sheet via le lien ci-dessus."""
        
        # Ajouter le lien LangSmith si disponible
        if langsmith_available:
            project_url = f"https://smith.langchain.com/projects/{LANGSMITH_CONFIG['LANGCHAIN_PROJECT']}"
            response += f"""

üí∞ **Statistiques d√©taill√©es** (tokens, co√ªts, performance) :
üîó {project_url}
"""
    
    state["messages"].append(AIMessage(content=response))
       
    return state
# =============================================================================
# CONSTRUCTION DU GRAPHE (APR√àS D√âFINITION DES FONCTIONS)
# =============================================================================

def build_graph() -> StateGraph:
    """Construit le graphe LangGraph"""
    
    workflow = StateGraph(AgentState)
    
    # Ajout des n≈ìuds
    workflow.add_node("parse_query", parse_user_query)
    workflow.add_node("fetch_data", fetch_api_data)
    workflow.add_node("process_data", process_data)
    workflow.add_node("create_sheet", create_google_sheet)
    workflow.add_node("respond", generate_response)
    
    # D√©finition des connexions
    workflow.add_edge(START, "parse_query")
    workflow.add_edge("parse_query", "fetch_data")
    workflow.add_edge("fetch_data", "process_data")
    workflow.add_edge("process_data", "create_sheet")
    workflow.add_edge("create_sheet", "respond")
    workflow.add_edge("respond", END)
    
    return workflow.compile()

# Instance du graphe pour l'export
graph = build_graph()

# =============================================================================
# UTILITAIRES D'√âTAT
# =============================================================================

def get_initial_state() -> AgentState:
    """Configuration de l'√©tat initial par d√©faut"""
    return {
        "messages": [],
        "api_url": DEFAULT_API_URL,
        "user_query": "",
        "extracted_params": None,
        "api_data": None,
        "processed_data": None,
        "sheets_url": "",
        "error": ""
    }

# =============================================================================
# FONCTION D'EX√âCUTION AVEC TRACING GLOBAL
# =============================================================================

def run_agent_with_tracing(user_input: str, run_name: str = None) -> AgentState:
    """Ex√©cute l'agent avec un tracing global de la session"""
    
    if run_name is None:
        run_name = f"agent_run_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    
    trace_context = None
    if langsmith_client:
        try:
            trace_context = langsmith_client.trace(
                name=run_name,
                tags=["agent_execution", "full_pipeline"],
                metadata={"user_input": user_input}
            ).__enter__()
        except:
            pass
    
    try:
        # √âtat initial
        initial_state = get_initial_state()
        initial_state["messages"] = [HumanMessage(content=user_input)]
        
        if trace_context:
            trace_context.update(inputs={"user_input": user_input})
        
        log_debug(f"D√©marrage de l'agent avec input: {user_input}")
        
        # Ex√©cution du graphe
        result = graph.invoke(initial_state)
        
        if trace_context:
            trace_context.update(outputs={
                "success": True,
                "final_state": {
                    "sheets_url": result.get("sheets_url"),
                    "processed_data_count": len(result.get("processed_data", [])),
                    "error": result.get("error")
                }
            })
        
        return result
        
    except Exception as e:
        error_msg = f"Erreur lors de l'ex√©cution de l'agent: {str(e)}"
        if trace_context:
            trace_context.update(outputs={"success": False, "error": error_msg})
        print(f"‚ùå {error_msg}")
        raise
    
    finally:
        if trace_context:
            trace_context.__exit__(None, None, None)

# =============================================================================
# FONCTION DE TEST PRINCIPALE
# =============================================================================

def main():
    """Fonction principale pour tester l'agent"""
    try:
        print("üöÄ D√©marrage de l'agent API to Sheets")
        print(f"üìã Configuration:")
        print(f"   - Mod√®le OpenAI: {OPENAI_MODEL}")
        print(f"   - API par d√©faut: {DEFAULT_API_URL}")
        print(f"   - Limite par d√©faut: {DEFAULT_LIMIT}")
        print(f"   - LangSmith activ√©: {'‚úÖ' if langsmith_client else '‚ùå'}")
        print(f"   - Debug activ√©: {'‚úÖ' if DEBUG else '‚ùå'}")
        print(f"   - Environnement valide: {'‚úÖ' if env_valid else '‚ùå'}")
        print()
        
        if not env_valid:
            print("‚ö†Ô∏è Configuration incompl√®te - certaines fonctionnalit√©s peuvent ne pas fonctionner")
        
        # Test avec une requ√™te exemple
        test_query = "r√©cup√®re 5 posts avec title et id"
        print(f"üß™ Test avec la requ√™te: '{test_query}'")
        
        result = run_agent_with_tracing(test_query, "test_execution")
        
        if result.get("error"):
            print(f"‚ùå Erreur: {result['error']}")
        else:
            print("‚úÖ Ex√©cution r√©ussie!")
            if result.get("sheets_url"):
                print(f"üìä Google Sheet cr√©√©: {result['sheets_url']}")
        
    except Exception as e:
        print(f"‚ùå Erreur lors de l'ex√©cution: {e}")
        return 1
    
    return 0

# =============================================================================
# POINT D'ENTR√âE
# =============================================================================

if __name__ == "__main__":
    exit(main())

# =============================================================================
# EXPORT POUR LANGGRAPH STUDIO
# =============================================================================

# Ces variables et fonctions sont export√©es pour LangGraph Studio
__all__ = [
    'graph',
    'AgentState', 
    'get_initial_state',
    'run_agent_with_tracing',
    'parse_user_query',
    'fetch_api_data',
    'process_data', 
    'create_google_sheet',
    'generate_response'
]

# =============================================================================
# CONFIGURATION LANGGRAPH STUDIO
# =============================================================================

# Metadata pour LangGraph Studio
GRAPH_METADATA = {
    "title": "API to Google Sheets Agent",
    "description": "Agent qui r√©cup√®re des donn√©es d'APIs et les exporte vers Google Sheets",
    "version": "1.0.0",
    "author": "Your Name",
    "tags": ["api", "google-sheets", "data-export", "langgraph"],
    "requirements": [
        "openai", 
        "gspread", 
        "google-auth",
        "requests",
        "langchain-openai",
        "langgraph",
        "langsmith"
    ],
    "configuration": {
        "required_env_vars": [
            "OPENAI_API_KEY",
            "GOOGLE_CREDENTIALS_PATH"
        ],
        "optional_env_vars": [
            "LANGSMITH_API_KEY",
            "GOOGLE_PERSONAL_EMAIL",
            "DEFAULT_API_URL",
            "DEBUG"
        ]
    }
}

# Configuration par d√©faut pour les tests dans Studio
DEFAULT_TEST_CONFIG = {
    "user_input": "r√©cup√®re 5 posts avec title et id",
    "api_url": DEFAULT_API_URL,
    "expected_fields": ["title", "id"],
    "expected_limit": 5
}

# =============================================================================
# CONFIGURATION DE D√âMARRAGE POUR LANGGRAPH STUDIO
# =============================================================================

print(f"üîß LangGraph Agent charg√© - Configuration:")
print(f"   - OpenAI: {'‚úÖ' if OPENAI_API_KEY else '‚ùå'}")
print(f"   - Google Sheets: {'‚úÖ' if gc else '‚ùå'}")
print(f"   - LangSmith: {'‚úÖ' if langsmith_client else '‚ùå'}")
print(f"   - Debug: {'‚úÖ' if DEBUG else '‚ùå'}")

if not env_valid:
    print("‚ö†Ô∏è Configuration incompl√®te - v√©rifiez votre fichier .env")
    print("üìù Variables requises:")
    print("   - OPENAI_API_KEY")
    print("   - GOOGLE_CREDENTIALS_PATH (fichier google-credentials.json)")
    print("üìù Variables optionnelles:")
    print("   - LANGSMITH_API_KEY")
    print("   - GOOGLE_PERSONAL_EMAIL")
else:
    print("‚úÖ Agent pr√™t √† √™tre utilis√© !")

# Afficher un r√©sum√© de la configuration
print("\nüìã R√©sum√© de la configuration:")
print(f"   - Mod√®le OpenAI: {OPENAI_MODEL}")
print(f"   - Temperature: {OPENAI_TEMPERATURE}")
print(f"   - API timeout: {API_TIMEOUT}s")
print(f"   - Limite par d√©faut: {DEFAULT_LIMIT} posts")
print(f"   - Limite max: {MAX_LIMIT} posts")
print(f"   - URL API par d√©faut: {DEFAULT_API_URL}")
print(f"   - Dossier Google Sheets: {SHEETS_FOLDER_NAME}")
print(f"   - Pr√©fixe des sheets: {SHEETS_DEFAULT_TITLE_PREFIX}")

if GOOGLE_PERSONAL_EMAIL:
    print(f"   - Email personnel: {GOOGLE_PERSONAL_EMAIL}")

if langsmith_client:
    print(f"   - Projet LangSmith: {LANGSMITH_CONFIG.get('LANGCHAIN_PROJECT', 'N/A')}")

print("\nüîó Pour tester l'agent:")
print('   result = run_agent_with_tracing("r√©cup√®re 5 posts avec title et id")')
print("   print(result)")

print("\nüéØ Agent pr√™t pour LangGraph Studio !")